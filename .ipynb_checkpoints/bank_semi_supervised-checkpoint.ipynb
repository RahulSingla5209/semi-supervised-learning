{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2984eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baec99",
   "metadata": {},
   "source": [
    "# data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2f971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \\\n",
       "0  unknown    5   may       261         1     -1         0  unknown  no   \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no   \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no   \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no   \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no   \n",
       "\n",
       "   weight  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./bank/bank-full.csv\", sep = \";\")\n",
    "data[\"weight\"] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a5e9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4189</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>14</td>\n",
       "      <td>jul</td>\n",
       "      <td>897</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>292</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>10</td>\n",
       "      <td>jul</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>-125</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>6</td>\n",
       "      <td>feb</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>53</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>mar</td>\n",
       "      <td>257</td>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>aug</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job   marital  education default  balance housing loan  \\\n",
       "0   68     retired  divorced  secondary      no     4189      no   no   \n",
       "1   35  management    single   tertiary      no      292      no  yes   \n",
       "2   36   housemaid   married    primary      no     -125      no  yes   \n",
       "3   39    services   married  secondary      no       53      no   no   \n",
       "4   30  technician    single  secondary      no        5      no   no   \n",
       "\n",
       "     contact  day month  duration  campaign  pdays  previous poutcome    y  \\\n",
       "0  telephone   14   jul       897         2     -1         0  unknown  yes   \n",
       "1   cellular   10   jul       220         1     -1         0  unknown   no   \n",
       "2   cellular    6   feb        91         2     -1         0  unknown   no   \n",
       "3    unknown    5   mar       257         1    394         1  failure  yes   \n",
       "4   cellular   19   aug       120         6     -1         0  unknown   no   \n",
       "\n",
       "   weight  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, stratify = data[\"y\"], \n",
    "                                         train_size=0.4)\n",
    "train_data = train_data.reset_index(drop=True).copy()\n",
    "test_data = test_data.reset_index(drop=True).copy()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65da0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the numerical feature names.\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"balance\",\n",
    "    \"duration\",\n",
    "    \"campaign\",\n",
    "    \"previous\",\n",
    "    \"pdays\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = [\n",
    "    \"job\",\n",
    "    \"marital\",\n",
    "    \"education\",\n",
    "    \"default\",\n",
    "    \"housing\",\n",
    "    \"loan\",\n",
    "    \"contact\",\n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"poutcome\"\n",
    "]\n",
    "\n",
    "WEIGHT_COLUMN_NAME = \"weight\"\n",
    "\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"y\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = [\"no\", \"yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4da1c",
   "metadata": {},
   "source": [
    "# Embedding Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11191705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(model, filename):\n",
    "    embeddings = {}\n",
    "\n",
    "    for layer in model.layers: \n",
    "        if \"_embedding\" in  layer.get_config()[\"name\"]:\n",
    "            col_name = layer.get_config()[\"name\"].split(\"_embedding\")[0]\n",
    "            if col_name not in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "                continue\n",
    "            embeddings[col_name] = {}\n",
    "            for idx, cat in enumerate(CATEGORICAL_FEATURES_WITH_VOCABULARY[col_name]):\n",
    "                if \"mask\" in cat:\n",
    "                    continue\n",
    "                embeddings[col_name][cat] = layer.get_weights()[0][idx]\n",
    "            \n",
    "    with open(filename, 'wb') as config_dictionary_file:\n",
    "        pickle.dump(embeddings, config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65872737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(model, filename):\n",
    "    with open(filename, 'rb') as config_dictionary_file:\n",
    "        embeddings = pickle.load(config_dictionary_file)\n",
    "    \n",
    "    for layer in model.layers: \n",
    "        if \"_embedding\" in  layer.get_config()[\"name\"]:\n",
    "            col_name = layer.get_config()[\"name\"].split(\"_embedding\")[0]\n",
    "            if col_name not in CATEGORICAL_FEATURES_WITH_VOCABULARY:\n",
    "                continue\n",
    "                \n",
    "            layer.set_weights([np.array(list(\n",
    "                        [\n",
    "                            embeddings[col_name][c] \\\n",
    "                                             for c in CATEGORICAL_FEATURES_WITH_VOCABULARY[col_name]\n",
    "                        ]\n",
    "            ))])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf900c",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - MLM for numerical data (Static Masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cfba0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Configure the hyperparameters\n",
    "The hyperparameters includes model architecture and training configurations.\n",
    "\"\"\"\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 265\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_TRANSFORMER_BLOCKS = 3  # Number of transformer blocks.\n",
    "NUM_HEADS = 4  # Number of attention heads.\n",
    "EMBEDDING_DIMS = 8  # Embedding dimensions of the categorical features.\n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]  # MLP hidden layer units, as factors of the number of inputs.\n",
    "NUM_MLP_BLOCKS = 2  # Number of MLP blocks in the baseline model.\n",
    "\n",
    "\"\"\"\n",
    "## Implement data reading pipeline\n",
    "We define an input function that reads and parses the file, then converts features\n",
    "and labels into a[`tf.data.Dataset`](https://www.tensorflow.org/guide/datasets)\n",
    "for training or evaluation.\n",
    "\"\"\"\n",
    "def prepare_example(features, target):\n",
    "    # target_index = target_label_lookup(target)\n",
    "    target = int(target)\n",
    "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    return features, target, weights\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        #column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa15ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Create model inputs\n",
    "Now, define the inputs for the models as a dictionary, where the key is the feature name,\n",
    "and the value is a `keras.layers.Input` tensor with the corresponding feature shape\n",
    "and data type.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Encode features\n",
    "The `encode_inputs` method returns `encoded_categorical_feature_list` and `numerical_feature_list`.\n",
    "We encode the categorical features as embeddings, using a fixed `embedding_dims` for all the features,\n",
    "regardless their vocabulary sizes. This is required for the Transformer model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, embedding_dims):\n",
    "\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "\n",
    "    for feature_name in inputs:\n",
    "        # Get the vocabulary of the categorical feature.\n",
    "        vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "\n",
    "        # Create a lookup to convert string values to an integer indices.\n",
    "        # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "        # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "        lookup = layers.StringLookup(\n",
    "            vocabulary=vocabulary,\n",
    "            mask_token=None,\n",
    "            num_oov_indices=1,\n",
    "            output_mode=\"int\",\n",
    "        )\n",
    "\n",
    "        # Convert the string input values into integer indices.\n",
    "        encoded_feature = lookup(inputs[feature_name])-1\n",
    "\n",
    "        # Create an embedding layer with the specified dimensions.\n",
    "        embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims,\n",
    "                name=feature_name+\"_embedding\"\n",
    "            )\n",
    "\n",
    "        # Convert the index values to embedding representations.\n",
    "        encoded_categorical_feature = embedding(encoded_feature)\n",
    "        encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "\n",
    "    return encoded_categorical_feature_list\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Implement an MLP block\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    return keras.Sequential(mlp_layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5c8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Implement a training and evaluation procedure\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    model,\n",
    "    train_data_file,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, verbose=1\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94b91226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count 75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46, 57, 38, 34, 41, 54,  2, 29, 67, 74],\n",
       "       [51, 58, 37, 34, 41, 54,  2, 29, 67, 74],\n",
       "       [44, 57, 37, 34, 41, 55,  2, 29, 67, 74],\n",
       "       [43, 57, 39, 34, 41, 54,  2, 29, 67, 74],\n",
       "       [53, 58, 39, 34, 40, 54,  2, 29, 67, 74]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_data = data.copy()\n",
    "masked_data.drop(columns = NUMERIC_FEATURE_NAMES, inplace=True)\n",
    "masked_data.drop(columns = TARGET_FEATURE_NAME, inplace=True)\n",
    "masked_data.drop(columns = WEIGHT_COLUMN_NAME, inplace=True)\n",
    "\n",
    "le=LabelEncoder()\n",
    "all_data = []\n",
    "for f in CATEGORICAL_FEATURE_NAMES:\n",
    "    all_data = all_data + masked_data[f].apply(lambda x: f+str(x)).values.tolist()\n",
    "    \n",
    "n = len(masked_data)\n",
    "cat_data = le.fit_transform(all_data).reshape(len(CATEGORICAL_FEATURE_NAMES),n).T\n",
    "cat_count = len(np.unique(cat_data))\n",
    "print(\"Total token count\", cat_count)\n",
    "cat_data[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37f0668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>weight</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>mask9</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>mask8</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>mask2</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mask7</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>mask6</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>mask5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mask0</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>divorced</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>mask6</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>mask4</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>mask3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            job   marital  education default housing   loan  contact    day  \\\n",
       "0    management   married   tertiary      no     yes     no  unknown      5   \n",
       "1    technician    single  secondary      no     yes     no  unknown      5   \n",
       "2  entrepreneur   married      mask2      no     yes    yes  unknown      5   \n",
       "3   blue-collar   married    unknown      no     yes     no  unknown  mask7   \n",
       "4       unknown    single    unknown      no      no     no    mask6      5   \n",
       "5    management   married   tertiary      no     yes  mask5  unknown      5   \n",
       "6         mask0    single   tertiary      no     yes    yes  unknown      5   \n",
       "7  entrepreneur  divorced   tertiary     yes     yes     no    mask6      5   \n",
       "8       retired   married    primary      no   mask4     no  unknown      5   \n",
       "9    technician    single  secondary   mask3     yes     no  unknown      5   \n",
       "\n",
       "   month poutcome  weight  label  \n",
       "0    may    mask9       1     74  \n",
       "1  mask8  unknown       1     67  \n",
       "2    may  unknown       1     37  \n",
       "3    may  unknown       1     29  \n",
       "4    may  unknown       1      2  \n",
       "5    may  unknown       1     54  \n",
       "6    may  unknown       1     46  \n",
       "7    may  unknown       1      2  \n",
       "8    may  unknown       1     41  \n",
       "9    may  unknown       1     34  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_pos = random.randint(len(CATEGORICAL_FEATURE_NAMES), size=(n))\n",
    "mask_label = []\n",
    "for i in range(n):\n",
    "    mask_label = mask_label + [cat_data[i, masks_pos[i]]]\n",
    "    masked_data.iloc[i, masks_pos[i]] = \"mask\"+str(masks_pos[i])\n",
    "\n",
    "le2=LabelEncoder()\n",
    "mask_label = le2.fit_transform(mask_label)    \n",
    "masked_data[WEIGHT_COLUMN_NAME]=data[WEIGHT_COLUMN_NAME]\n",
    "masked_data[\"label\"] = mask_label\n",
    "CSV_HEADER_UN = masked_data.columns\n",
    "masked_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "744717f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Define dataset metadata\n",
    "Here, we define the metadata of the dataset that will be useful for reading and parsing\n",
    "the data into input features, and encoding the input features with respect to their types.\n",
    "\"\"\"\n",
    "# A dictionary of the categorical features and their vocabulary.\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {}\n",
    "\n",
    "\n",
    "for f in CATEGORICAL_FEATURE_NAMES:\n",
    "    masked_data[f] = masked_data[f].astype(\"str\")\n",
    "    CATEGORICAL_FEATURES_WITH_VOCABULARY[f] =\\\n",
    "        sorted(list(masked_data[f].unique()))\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e25e27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we store the training and test data in separate CSV files.\n",
    "\"\"\"\n",
    "\n",
    "train_data_file = \"train_data.csv\"\n",
    "\n",
    "masked_data.to_csv(train_data_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98db30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of all the input features.\n",
    "FEATURE_NAMES = CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"label\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = masked_data[\"label\"].unique()\n",
    "\n",
    "# A list of column default values for each feature.\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in [WEIGHT_COLUMN_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER_UN\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b77c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',\n",
       "       'day', 'month', 'poutcome', 'weight', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_HEADER_UN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d45588b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weights: 36659\n",
      "Start training the model...\n",
      "Epoch 1/10\n",
      "171/171 [==============================] - 10s 32ms/step - loss: 1.5880 - accuracy: 0.5553\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.1353 - accuracy: 0.6273\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.0636 - accuracy: 0.6431\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 1.0248 - accuracy: 0.6531\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 1.0030 - accuracy: 0.6592\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.9897 - accuracy: 0.6623\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 5s 29ms/step - loss: 0.9788 - accuracy: 0.6638\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.9691 - accuracy: 0.6671\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.9621 - accuracy: 0.6675\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 5s 28ms/step - loss: 0.9575 - accuracy: 0.6679\n",
      "Model training finished\n"
     ]
    }
   ],
   "source": [
    "def create_tabtransformer_classifier(\n",
    "    num_transformer_blocks,\n",
    "    num_heads,\n",
    "    embedding_dims,\n",
    "    mlp_hidden_units_factors,\n",
    "    dropout_rate,\n",
    "    use_column_embedding=False,\n",
    "):\n",
    "\n",
    "    # Create model inputs.\n",
    "    inputs = create_model_inputs()\n",
    "    \n",
    "    # encode features.\n",
    "    encoded_categorical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # Stack categorical feature embeddings for the Tansformer.\n",
    "    encoded_categorical_features = tf.stack(encoded_categorical_feature_list, axis=1)\n",
    "\n",
    "    # Add column embedding to categorical feature embeddings.\n",
    "    if use_column_embedding:\n",
    "        num_columns = encoded_categorical_features.shape[1]\n",
    "        column_embedding = layers.Embedding(\n",
    "            input_dim=num_columns, output_dim=embedding_dims\n",
    "        )\n",
    "        column_indices = tf.range(start=0, limit=num_columns, delta=1)\n",
    "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
    "            column_indices\n",
    "        )\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for block_idx in range(num_transformer_blocks):\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dims,\n",
    "            dropout=dropout_rate,\n",
    "            name=f\"multihead_attention_{block_idx}\",\n",
    "        )(encoded_categorical_features, encoded_categorical_features)\n",
    "        # Skip connection 1.\n",
    "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
    "            [attention_output, encoded_categorical_features]\n",
    "        )\n",
    "        # Layer normalization 1.\n",
    "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
    "        # Feedforward.\n",
    "        feedforward_output = create_mlp(\n",
    "            hidden_units=[embedding_dims],\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{block_idx}\",\n",
    "        )(x)\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
    "        # Layer normalization 2.\n",
    "        encoded_categorical_features = layers.LayerNormalization(\n",
    "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
    "        )(x)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    categorical_features = layers.Flatten(name=\"dyanmic_embedding\")(encoded_categorical_features)\n",
    "\n",
    "    # Compute MLP hidden_units.\n",
    "    mlp_hidden_units = [\n",
    "        factor * categorical_features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # Create final MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(categorical_features)\n",
    "\n",
    "    # Add a sigmoid as a binary classifer.\n",
    "    outputs = layers.Dense(units=len(TARGET_LABELS), \n",
    "                           activation=\"softmax\", name=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "tabtransformer_model = create_tabtransformer_classifier(\n",
    "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "save_embeddings(tabtransformer_model, 'untrained_embeddings_bank.dictionary')\n",
    "\n",
    "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
    "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")\n",
    "\n",
    "\"\"\"\n",
    "Let's train and evaluate the TabTransformer model:\n",
    "\"\"\"\n",
    "\n",
    "history, tabtransformer_model = run_experiment(\n",
    "    model=tabtransformer_model,\n",
    "    train_data_file=train_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9df8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(tabtransformer_model,\n",
    "                'unsupervised_trained_embeddings_bank.dictionary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3dc957",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6351b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beee8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = data.columns\n",
    "\n",
    "# A list of all the input features.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "for f in CATEGORICAL_FEATURE_NAMES:\n",
    "    \n",
    "    train_data[f] = train_data[f].astype(\"str\")\n",
    "    test_data[f] = test_data[f].astype(\"str\")\n",
    "    \n",
    "    CATEGORICAL_FEATURES_WITH_VOCABULARY[f] =\\\n",
    "                    sorted(list(train_data[f].unique()))\n",
    "\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"y\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = train_data[TARGET_FEATURE_NAME].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False, header=True)\n",
    "test_data.to_csv(test_data_file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d995b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Configure the hyperparameters\n",
    "The hyperparameters includes model architecture and training configurations.\n",
    "\"\"\"\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 265\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "NUM_TRANSFORMER_BLOCKS = 3  # Number of transformer blocks.\n",
    "NUM_HEADS = 4  # Number of attention heads.\n",
    "EMBEDDING_DIMS = 8  # Embedding dimensions of the categorical features.\n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]  # MLP hidden layer units, as factors of the number of inputs.\n",
    "NUM_MLP_BLOCKS = 2  # Number of MLP blocks in the baseline model.\n",
    "\n",
    "\"\"\"\n",
    "## Implement data reading pipeline\n",
    "We define an input function that reads and parses the file, then converts features\n",
    "and labels into a[`tf.data.Dataset`](https://www.tensorflow.org/guide/datasets)\n",
    "for training or evaluation.\n",
    "\"\"\"\n",
    "\n",
    "target_label_lookup = layers.StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "def prepare_example(features, target):\n",
    "    target_index = target_label_lookup(target)\n",
    "    # target = int(target)\n",
    "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    print(target)\n",
    "    return features, target, weights\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        #column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    return dataset.cache()\n",
    "\n",
    "\"\"\"\n",
    "## Create model inputs\n",
    "Now, define the inputs for the models as a dictionary, where the key is the feature name,\n",
    "and the value is a `keras.layers.Input` tensor with the corresponding feature shape\n",
    "and data type.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Encode features\n",
    "The `encode_inputs` method returns `encoded_categorical_feature_list` and `numerical_feature_list`.\n",
    "We encode the categorical features as embeddings, using a fixed `embedding_dims` for all the features,\n",
    "regardless their vocabulary sizes. This is required for the Transformer model.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, embedding_dims):\n",
    "\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "\n",
    "            # Get the vocabulary of the categorical feature.\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=1,\n",
    "                output_mode=\"int\",\n",
    "                name = feature_name+\"_string_lookup\"\n",
    "            )\n",
    "\n",
    "            # Convert the string input values into integer indices.\n",
    "            encoded_feature = lookup(inputs[feature_name])-1\n",
    "\n",
    "            # Create an embedding layer with the specified dimensions.\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims,\n",
    "                name=feature_name+\"_embedding\"\n",
    "            )\n",
    "\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_categorical_feature = embedding(encoded_feature)\n",
    "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Use the numerical features as-is.\n",
    "            numerical_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "            numerical_feature_list.append(numerical_feature)\n",
    "\n",
    "    return encoded_categorical_feature_list, numerical_feature_list\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Implement an MLP block\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    return keras.Sequential(mlp_layers, name=name)\n",
    "\n",
    "\"\"\"\n",
    "## Implement a training and evaluation procedure\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    model,\n",
    "    train_data_file,\n",
    "    test_data_file,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "    validation_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, validation_data=validation_dataset\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(validation_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac41ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tabtransformer_classifier(\n",
    "    num_transformer_blocks,\n",
    "    num_heads,\n",
    "    embedding_dims,\n",
    "    mlp_hidden_units_factors,\n",
    "    dropout_rate,\n",
    "    use_column_embedding=False,\n",
    "):\n",
    "\n",
    "    # Create model inputs.\n",
    "    inputs = create_model_inputs()\n",
    "    # encode features.\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # Stack categorical feature embeddings for the Tansformer.\n",
    "    encoded_categorical_features = tf.stack(encoded_categorical_feature_list, axis=1)\n",
    "    # Concatenate numerical features.\n",
    "    numerical_features = layers.concatenate(numerical_feature_list)\n",
    "\n",
    "    # Add column embedding to categorical feature embeddings.\n",
    "    if use_column_embedding:\n",
    "        num_columns = encoded_categorical_features.shape[1]\n",
    "        column_embedding = layers.Embedding(\n",
    "            input_dim=num_columns, output_dim=embedding_dims\n",
    "        )\n",
    "        column_indices = tf.range(start=0, limit=num_columns, delta=1)\n",
    "        encoded_categorical_features = encoded_categorical_features + column_embedding(\n",
    "            column_indices\n",
    "        )\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for block_idx in range(num_transformer_blocks):\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embedding_dims,\n",
    "            dropout=dropout_rate,\n",
    "            name=f\"multihead_attention_{block_idx}\",\n",
    "        )(encoded_categorical_features, encoded_categorical_features)\n",
    "        # Skip connection 1.\n",
    "        x = layers.Add(name=f\"skip_connection1_{block_idx}\")(\n",
    "            [attention_output, encoded_categorical_features]\n",
    "        )\n",
    "        # Layer normalization 1.\n",
    "        x = layers.LayerNormalization(name=f\"layer_norm1_{block_idx}\", epsilon=1e-6)(x)\n",
    "        # Feedforward.\n",
    "        feedforward_output = create_mlp(\n",
    "            hidden_units=[embedding_dims],\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{block_idx}\",\n",
    "        )(x)\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add(name=f\"skip_connection2_{block_idx}\")([feedforward_output, x])\n",
    "        # Layer normalization 2.\n",
    "        encoded_categorical_features = layers.LayerNormalization(\n",
    "            name=f\"layer_norm2_{block_idx}\", epsilon=1e-6\n",
    "        )(x)\n",
    "\n",
    "    # Flatten the \"contextualized\" embeddings of the categorical features.\n",
    "    categorical_features = layers.Flatten(name=\"dyanmic_embedding\")(encoded_categorical_features)\n",
    "    # Apply layer normalization to the numerical features.\n",
    "    numerical_features = layers.LayerNormalization(epsilon=1e-6)(numerical_features)\n",
    "    # Prepare the input for the final MLP block.\n",
    "    features = layers.concatenate([categorical_features, numerical_features])\n",
    "\n",
    "    # Compute MLP hidden_units.\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # Create final MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "\n",
    "    # Add a sigmoid as a binary classifer.\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "tabtransformer_model = create_tabtransformer_classifier(\n",
    "    num_transformer_blocks=NUM_TRANSFORMER_BLOCKS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "print(\"Total model weights:\", tabtransformer_model.count_params())\n",
    "keras.utils.plot_model(tabtransformer_model, show_shapes=True, rankdir=\"LR\")\n",
    "\n",
    "\"\"\"\n",
    "Let's train and evaluate the TabTransformer model:\n",
    "\"\"\"\n",
    "\n",
    "tabtransformer_model = load_embeddings(tabtransformer_model, \n",
    "                                       'untrained_embeddings_bank.dictionary')\n",
    "\n",
    "history, tabtransformer_model = run_experiment(\n",
    "    model=tabtransformer_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd04a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02638e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb85101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
